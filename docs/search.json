[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m Himadri Mandal, 17, you might know me as quirtt from Discord/AoPS, as I use that name on the internet. I am a freshman at ISI Kolkata, India studying Statistics (mostly Mathematics so far, though. lol!). Confession: I might like mathematics more than statistics - I really hope I enjoy statistics as I learn more of it, because I would be sad otherwise.\nAt any point in the day I am found doing the following things: sleep, learn weird math/cs, watch anime, cope through university lectures, read some ML paper, goofing around with friends, playing table tennis. Ah well. I have been recently getting more and more involved in AI and AI alignment, too.\nIf you find me interesting - feel free to shoot me a mail at mandalhimadri06@gmail.com or send me a “Hi!” on Discord."
  },
  {
    "objectID": "no_show/welcome/index.html",
    "href": "no_show/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/nelson/nelson.html",
    "href": "posts/nelson/nelson.html",
    "title": "So Far Yet So Close: How Independence is Almost Dependence",
    "section": "",
    "text": "Imagine two continuous random variables seemingly unrelated and free from any influence from each other. It’s a common assumption in probability theory that independence implies a lack of any relationship between variables.\nHowever, a fascinating theorem challenges this notion, showing that from any two independent continuous random variables, we can construct new deterministically dependent variables that not only share the same distributions but also have joint distributions that are arbitrarily close.\nIn other words, independence can be deceptive, leading us to a realm where variables are closer than we think. Let’s explore this intriguing theorem and its implications.\n(If you could link me up with a paper that talks about this theorem, please do. I couldn’t find it. This theorem is apparently proven by “Nelson”.)"
  },
  {
    "objectID": "posts/nelson/nelson.html#theorem",
    "href": "posts/nelson/nelson.html#theorem",
    "title": "So Far Yet So Close: How Independence is Almost Dependence",
    "section": "Theorem",
    "text": "Theorem\n\nLet \\(X,Y\\) with \\(F_X, F_Y \\uparrow,\\) be independent continuous random variables on \\((\\mathbb{R}, \\mathcal{B}, P)\\). For all \\(\\epsilon &gt; 0\\) there exist deterministically dependent \\(U,V\\) on the same probability space \\(F_U = F_X, F_V = F_Y\\) and \\(\\sup_{(a,b) \\in \\mathbb{R}^2} |F_{U,V}(a,b) - F_{X,Y}(a,b)| &lt; \\epsilon\\).\n\nHere is the proof I came up with:"
  },
  {
    "objectID": "posts/nelson/nelson.html#proof",
    "href": "posts/nelson/nelson.html#proof",
    "title": "So Far Yet So Close: How Independence is Almost Dependence",
    "section": "Proof",
    "text": "Proof\nWe can instead work with the random variables \\(\\frac{1}{1+e^{X}}\\), and rename \\(Y\\) similarly too, to work with random variables bounded in \\([0,1]\\).\nFix positive integer \\(n\\), and obtain \\(\\{a_{0,0}=0 &lt; \\cdots &lt; a_{0,n-1} &lt; a_{1,0} &lt; \\cdots &lt; a_{1,n-1} &lt; \\cdots &lt; a_{n-1,0} &lt; \\cdots &lt; a_{n-1,n}=1\\}\\) and \\(\\{b_{0,0}=0 &lt; \\cdots &lt; b_{0,n-1} &lt; b_{1,0} &lt; \\cdots &lt; b_{1,n-1} &lt; \\cdots &lt; b_{n-1,0} &lt; \\cdots &lt; b_{n-1,n}=1\\}\\)\n\n\n\n\n\nsuch that \\[F_X(a_{j,0}) - F_X(a_{j-1, 0}) = \\frac{1}{n}, \\ F_Y(b_{j,0}) - F_Y(b_{j-1, 0}) = \\frac{1}{n}\\] \\[F_X(a_{j,i}) - F_X(a_{j, i-1}) = \\frac{1}{n^2}, \\ F_Y(b_{j,i}) - F_Y(b_{j, i-1}) = \\frac{1}{n^2}\\] \\[\\implies F_X(a_{i,j}) = F_Y(b_{i,j}) = \\frac{i}{n} + \\frac{j}{n^2}\\]\n\\[I_{i,j} = \\{a_{i, j} \\leq x \\leq a_{i, j+1}\\}, \\ J_{j,i} = \\{b_{j, i} \\leq y \\leq b_{j, i+1}\\}\\] \\[I_i = \\cup_{j}I_{i,j}, \\ J_j = \\cup_{i}J_{j,i}\\] The idea is to reorder \\(X\\) in a way such that \\[x \\in I_{i,j} \\iff y \\in J_{j,i}\\]\nHence we would want something like this \\[P\\left(X \\in \\cup_j I_{i,j}\\right)\\cdot P\\left(Y \\in \\cup_i J_{j,i}\\right) = P\\left(X \\in \\cup_{j}I_{i,j} \\text{ and } Y \\in \\cup_{i}J_{j,i}\\right) \\] \\[= P\\left(U \\in \\cup_{j}I_{i,j} \\text{ and } V \\in \\cup_{i}J_{j,i}\\right)\\]\nLet \\(V \\equiv Y\\), we would want to construct a bijective function \\(g:[0,1] \\to [0,1]\\) such that for \\(y \\in J_{j,i}\\)\n\\[F_Y(y) - F_Y(b_{j,i}) = P\\left(b_{j,i} \\leq Y \\leq y\\right) \\stackrel{\\textcolor{red}{!}}{=} P\\left(b_{j,i} \\leq g(X) \\leq y\\right)\\] \\[\\stackrel{\\textcolor{red}{!}}{=}P\\left(a_{i,j} \\leq X \\leq g^{-1}(y)\\right) = F_X(g^{-1}(y)) - F_X(a_{i,j})\\]\n\\[F_X(g^{-1}(y))  = F_Y(y)+(F_X(a_{i,j}) - F_Y(b_{j,i}))\\] \\[\\stackrel{\\textcolor{red}{!}}{=}F_Y(y) + \\left((i-j) \\cdot \\left(\\frac{n-1}{n^2}\\right)\\right)\\] \\[x = g^{-1}(y) \\stackrel{\\textcolor{red}{!}}{=} F_X^{-1}\\left(F_Y(y) + \\left((i-j) \\cdot \\left(\\frac{n-1}{n^2}\\right)\\right)\\right)\\]\nThis is clearly measurable, and it is easy to check that this function indeed satisfies the \\(x \\in I_{i,j} \\iff y \\in J_{j,i}\\) condition. Take \\(U \\equiv g^{-1}(Y)\\).\nI will now be done if I show that \\(U\\) follows the same CDF as \\(X\\). For \\(x \\in I_{i,j}\\)\n\\[P\\left(a_{i,j} \\leq U \\leq x\\right)\\] \\[ = P\\left(a_{i,j} \\leq F_X^{-1}\\left(F_Y(Y) + \\left((i-j) \\cdot \\left(\\frac{n-1}{n^2}\\right)\\right)\\right) \\leq x\\right)\\] \\[= P\\left(F_X(a_{i,j}) \\leq F_Y(Y) + \\left((i-j) \\cdot \\left(\\frac{n-1}{n^2}\\right)\\right) \\leq F_X(x)\\right)\\] \\[= F_X(x) - F_X(a_{i,j}) = P(a_{i,j} \\leq X \\leq x)\\]\nThe last equality was legal because \\(F_X(a_{i,j}) - (F_X(a_{i,j}) - F_Y(b_{j,i})) = F_Y(b_{j,i}) \\geq 0\\).\nNow as \\(n \\to \\infty\\), their joints would get arbitrarily close.\n\\(\\blacksquare\\)\n(If you would like to use this proof, please email me.)\nUsing the same idea but fixing things up a little bit for the issues with invertibility, one could also prove the following"
  },
  {
    "objectID": "posts/zorn-and-aoc/zorn-and-aoc.html",
    "href": "posts/zorn-and-aoc/zorn-and-aoc.html",
    "title": "Axiom of Choice, the Zorn’s Lemma, and the Foundations of Mathematics: Set Theory Part I",
    "section": "",
    "text": "Mathematics has long been built on the sturdy foundation of intuition. From counting pebbles to solving complex equations, mathematicians have relied on their inner compass to navigate the abstract landscapes of numbers and shapes. But as the 19th century dawned, something intriguing and unsettling began to occur – mathematics, the bedrock of human knowledge, was on the brink of a seismic shift.\nThis piece goes into how this happened, what changed - and its consequences. Though I might not know a lot of mathematics, I firmly believe that this is one of the most interesting (while being accessible) parts of mathematics.\nAll of this begins with arguably the most famous paradox in mathematics, logic, and the like - the Russell’s paradox."
  },
  {
    "objectID": "posts/zorn-and-aoc/zorn-and-aoc.html#russells-paradox",
    "href": "posts/zorn-and-aoc/zorn-and-aoc.html#russells-paradox",
    "title": "Axiom of Choice, the Zorn’s Lemma, and the Foundations of Mathematics: Set Theory Part I",
    "section": "Russell’s Paradox",
    "text": "Russell’s Paradox\nLet \\(A\\) be the set of all sets that do not contain themselves. Does \\(A\\) contain itself?\n\\[\nA = \\{x : x \\not\\in x\\} \\text{. Is } A \\in A?\n\\]\n\nWell, if \\(A \\in A\\) then by the definition of \\(A\\), we get \\(A \\not \\in A\\). But if \\(A \\not\\in A\\) then \\(A \\in A\\). Poof.\nThis called for a need for formalism - intuition was just not enough. Here came Axiomatic Set Theory - one of the most famous systems of Axiomatic Set Theory is the Zermelo Fraenkel set theory. (Do click the link and read the axioms - they are fun! And everything makes sense at the end.)\nWell, how does the Russell’s paradox get resolved? One of the axioms deals with this head-on.\n\nAxiom Schema of Specification / Axiom of Restricted Comprehension\nGiven a parent set \\(z\\) we can construct a subset \\(S \\subseteq z\\) such that\n\\[\nS = \\{x \\in z : \\varphi(x)\\}\n\\]\n\nAlthough this defines how we can create subsets from a parent set, it DOESN’T talk about creating sets of elements that follow a formula. Infact, we will need a sort of \\(\\text{``set of all sets: X\"}\\) to talk about creating sets out of thin air.\nHowever this is NOT a set (In \\(\\text{ZF}\\)) . How do we prove this? Well, if \\(X\\) is the set of all sets, then \\(P(X) \\in X\\) which means there exists an injective function from \\(f:P(X)\\to X\\). But we know by Theorem 3 that \\(P(X) &gt;_{c} X\\). This is a Class."
  },
  {
    "objectID": "posts/zorn-and-aoc/zorn-and-aoc.html#axiom-of-choice",
    "href": "posts/zorn-and-aoc/zorn-and-aoc.html#axiom-of-choice",
    "title": "Axiom of Choice, the Zorn’s Lemma, and the Foundations of Mathematics: Set Theory Part I",
    "section": "Axiom of Choice",
    "text": "Axiom of Choice\nLet \\(I\\) be an index set with a family of sets indexed on this index set \\(\\{A_i\\}_{i \\in I}\\). Then there exists a choice function \\(f:I \\to A = \\cup_{i \\in I} A_i\\) such that \\(f(i) \\in A_i \\ \\forall i \\in I\\).\n\nThis makes “intuitive” sense and is something that “should” be true. However, this is an independent statement in \\(\\text{ZF}\\), which is to say - we CANNOT prove this by ONLY using the axioms of \\(\\text{ZF}\\). There is an equivalent formulation of this axiom (which is used more often)"
  },
  {
    "objectID": "posts/zorn-and-aoc/zorn-and-aoc.html#zorns-lemma",
    "href": "posts/zorn-and-aoc/zorn-and-aoc.html#zorns-lemma",
    "title": "Axiom of Choice, the Zorn’s Lemma, and the Foundations of Mathematics: Set Theory Part I",
    "section": "Zorn’s Lemma",
    "text": "Zorn’s Lemma\nIf \\(P\\) is a nonempty partially ordered set such that every chain has an upper bound in \\(P\\) then \\(P\\) has a maximal element.\n\nThere are quite a few words that need to be unpacked.\n\nDefinitions\n\nA binary relation \\(R\\) on a set \\(P\\) is a subset \\(R\\) of \\(P \\times P\\), \\((x,y) \\in R\\) and is often expressed as \\(xRy\\).\nA binary relation \\(R\\) is a partial order if\n\nReflexivity: \\(xRx\\), Transitivity: \\(xRy, yRz \\implies xRz\\).\nAntisymmetry: \\(xRy, yRx \\implies xRx\\).\n\nA partial order is called a linear order if any two elements are comparable.\nLet \\((P, \\leq)\\) be a poset (partially ordered set), a subset \\(C \\subseteq P\\) is called a chain if \\(C\\) has a linear order.\nLet \\(A \\subseteq P\\), an upper bound for \\(A\\) is an element \\(x \\in P\\) such that \\(y \\leq x, \\ \\forall y \\in A\\).\nAn \\(x \\in P\\) is called a maximal element if \\(\\not\\exists \\ y\\neq x : x \\leq y\\).\nA linearly ordered set is called well ordered if every nonempty subset has a first element."
  },
  {
    "objectID": "posts/zorn-and-aoc/zorn-and-aoc.html#zorn-and-axiom-of-choice-are-the-same",
    "href": "posts/zorn-and-aoc/zorn-and-aoc.html#zorn-and-axiom-of-choice-are-the-same",
    "title": "Axiom of Choice, the Zorn’s Lemma, and the Foundations of Mathematics: Set Theory Part I",
    "section": "Zorn and Axiom of Choice are the SAME!",
    "text": "Zorn and Axiom of Choice are the SAME!\nWe now conclude by proving that \\(\\text{Zorn}\\iff\\text{AoC}\\).\n\nTheorem 1 (\\(\\text{Zorn} \\implies \\text{AoC}\\)) \\[\n\\text{Zorn's Lemma} \\ \\implies \\text{Axiom of Choice}\n\\]\n\n(This proof was communicated to me by PSC. Sir at ISIK)\nConsider the following poset\n\\[\nP = \\{(J, f) : J \\subseteq I, f : J \\to A\\text{ such that }f(j) \\in A_j, \\forall j \\in J\\}\n\\]\nwith the partial order:\n\\[\n(J_1, f_1) \\preceq (J_2, f_2) \\text{ if } J_1 \\subseteq J_2 \\text{ and } f_2\\Bigg|_{J_1} = f_1 \\text{ ie. } f_2(x) = f_1(x), \\forall x \\in J_1\n\\]\nthen any chain \\(C = \\{(J_\\alpha, f_\\alpha) : \\alpha \\in Y\\}\\), has the trivial upperbound \\((\\cup J_\\alpha, f) : f\\Bigg |_{\\alpha} = f_\\alpha, \\forall \\alpha \\in Y\\). By Zorn’s Lemma, there exists a maximal element \\(f:J \\to A\\), if \\(J = I\\) , we are done. Otherwise, pick \\(j \\in I \\setminus J\\) since \\(A_j\\) is nonempty, pick \\(x \\in A_j\\) and consider \\(f^{*}:J \\cup \\{j\\} \\to A\\) such that \\(f(j) = x, f^{*}\\Bigg|_{J} = f\\), which contradicts maximality of \\(f\\).  \\(\\blacksquare\\)\n\n\nTheorem 2 (\\(\\text{AoC} \\implies \\text{Zorn}\\)) \\[\n\\text{Axiom of Choice} \\implies \\text{Zorn's Lemma}\n\\]\nThis is definitely trickier to prove compared to the previous implication. I use transfinite induction and ordinals here (but if you don’t know about them I will probably make a post on them. Till then, check out Napkin pg. 801.)\nLet \\((P, \\leq)\\) be the poset, where every chain has an upperbound. Assume there is no maximal element. Let \\(x_0\\) be any element in \\(P\\). By assumption \\(\\exists x_1\\) s.t. \\(x_0 \\leq x_1\\). But again, by assumption, \\(\\exists x_2\\) s.t. \\(x_0 \\leq x_1 \\leq x_2\\). Intuitively we create a chain \\(x_0 \\leq x_1 \\leq x_2 \\ \\cdots\\) which has an upper bound \\(x_\\omega\\), but since this isn’t the maximal element again - I get \\(x_0 \\leq x_1 \\leq x_2 \\leq \\cdots \\leq x_\\omega \\leq x_{\\omega+1} \\leq \\cdots\\). We must “eventually” run out.\nNow to formalize this: for any element \\(x \\in P\\) consider the set \\(S_x = \\{y \\in P : x \\lneq y\\}\\). Clearly all \\(S_x\\) are nonempty, because otherwise there is a maximal element. By AoC, there exists a choice function \\(f:P \\to \\cup_{x \\in P} S_x\\), such that \\(f(x) \\in S_x \\ \\forall x \\in P\\). Using transfinite induction:\n\nStep 1: \\(x_0 \\in P\\)\nTake \\(x_1 = f(x_0)\\). Then \\(x_0 \\leq x_1\\). Similarly, obtain \\(C_{i &lt; \\omega} = x_0 \\leq x_1 \\leq \\cdots\\).\nStep 2: Let \\(\\lambda\\) be a limit ordinal. Defining \\(x_\\lambda = u(C_{i &lt; \\lambda})\\) can be used to extend the chain.\nConsider the upper bound of this chain \\(x = u(C_{i &lt; \\lambda})\\). Clearly, \\(x\\) cannot be in \\(C\\), because otherwise, \\(\\exists k\\) s.t. \\(C \\ni x_k \\geq x = x_{k-1}\\) which forces \\(x = x_k = f(x)\\) which is not possible by the definition of \\(f\\). So, define \\(x_{\\lambda} = x\\).\n\nThen - keep doing this. So, you end up with a chain \\(C = x_0 \\leq x_1 \\leq \\cdots \\leq x_\\omega \\leq x_{\\omega + 1} \\leq \\cdots \\leq x_{\\omega + \\omega} \\leq \\cdots\\).\nTo finish we need magic: Hartogs’s theorem.\n\nHartogs’s Theorem\nGiven any set \\(X\\), there exists an ordinal \\(\\alpha\\) such that there is no injection \\(f:\\alpha \\to X\\).\n\nConsider the class of ordinals \\(\\alpha = \\{\\beta \\in \\text{Ord} \\ | \\ \\exists f:\\beta \\hookrightarrow X\\}\\). Using the power set axiom twice - we get that \\(\\mathcal{P}(X \\times X)\\) is a set. Consider the class \\(W\\) of all reflexive well orderings of subsets of \\(X\\), since this is a definable subclass of \\(\\mathcal{P}(X \\times X)\\), it is a set by Schema of Specification.\nThe class of all order types of well-orderings in \\(W\\) is a set by the axiom schema of replacement: \\((\\operatorname{Domain}(w), w) \\cong (\\beta, \\leq)\\) where \\(w\\) is a well-ordering on \\(\\operatorname{Domain}(w)\\) which gets mapped to the order type \\((\\beta, \\leq)\\).\nNow we can see that \\(W\\), a set, is precisely \\(\\alpha\\). Since every well-ordering of a subset of \\(X\\) defines an injective function from \\(\\beta \\hookrightarrow X\\) where \\(\\beta\\) is some ordinal. And the other side is true as well. To finish: \\(\\alpha\\) is a transitive set of ordinals, which means it is an ordinal itself. Ofcourse, then, \\(\\alpha\\) is the first ordinal with no injection \\(\\blacksquare\\).\n\nSo, the chain has to eventually end. We are done."
  },
  {
    "objectID": "posts/zorn-and-aoc/zorn-and-aoc.html#footnotes",
    "href": "posts/zorn-and-aoc/zorn-and-aoc.html#footnotes",
    "title": "Axiom of Choice, the Zorn’s Lemma, and the Foundations of Mathematics: Set Theory Part I",
    "section": "Footnotes",
    "text": "Footnotes\n\nTheorem 3 (Cantor’s Diagonal Argument) \\[X &lt;_{c} P(X) \\ \\forall \\ X\\]\n\nAssume for the sake of contradiction \\(P(X) =_{c} X\\) (where \\(=_{c}\\) means that there exists a bijection between the sets). Thus, there is a surjection \\(f:X \\to P(X)\\). Consider\n\\[\nA = \\{x \\in X: x \\not\\in f(x)\\}\n\\]\nBut since \\(f\\) is a surjection, \\(\\exists x_0 \\ f(x_0) = A\\) then\n\\[\nx_0 \\in A \\iff x_0 \\not\\in A.\n\\]\na contradiction. (This is pretty much the same idea as the famous proof of real numbers being uncountable.)"
  },
  {
    "objectID": "posts/a-cool-problem/polynomials-are-linear.html",
    "href": "posts/a-cool-problem/polynomials-are-linear.html",
    "title": "\\(k+1\\) points uniquely determine a \\(k\\) degree polynomial: A cool problem",
    "section": "",
    "text": "Reading the title: you are probably shouting “Lagrange Interpolation!!!” Yeah, sure, Lagrange is cool. But I will show you something cooler which ensures you don’t have to deal with the messy stuff."
  },
  {
    "objectID": "posts/a-cool-problem/polynomials-are-linear.html#problem-statement",
    "href": "posts/a-cool-problem/polynomials-are-linear.html#problem-statement",
    "title": "\\(k+1\\) points uniquely determine a \\(k\\) degree polynomial: A cool problem",
    "section": "Problem Statement",
    "text": "Problem Statement\nLet \\(k \\in \\mathbb{N}\\) and \\(t_1, \\dotsc, t_k \\in [0,1]\\) be distinct points. Let \\(\\mathcal{P}_{k-1}\\) be the space of polynomials of degree less than or equal to \\(k-1\\) with real coefficients. Show that there exist real numbers \\(a_1, \\dotsc, a_k\\) such that\n\\[\n\\int_0^1f(x)dx = \\sum_{j=1}^k a_jf(t_j)\n\\]\nfor all \\(f \\in \\mathcal{P}_{k-1}\\)."
  },
  {
    "objectID": "posts/a-cool-problem/polynomials-are-linear.html#solution",
    "href": "posts/a-cool-problem/polynomials-are-linear.html#solution",
    "title": "\\(k+1\\) points uniquely determine a \\(k\\) degree polynomial: A cool problem",
    "section": "Solution",
    "text": "Solution\nWhenever you try to prove something “uniquely” determines something; it’s always nice to try to find an isomorphism somewhere. Consider the linear map \\(S:\\mathcal{P}_{k-1} \\to \\mathbb{R}^k\\) such that\n\\[\nS(f) = (f(t_1), \\dotsc, f(t_k))\n\\]\n\nClaim 1: \\(S\\) is an isomorphism.\nSince \\(\\dim{\\mathcal{P}_{k-1}} = \\dim{\\mathbb{R}^k} = k\\), we would be done if we prove \\(\\mathcal{N}(S) = 0\\). Assume \\(S(f) = (0, 0, \\dotsc, 0)\\) which means \\(f\\) a \\(\\leq k-1\\) degree polynomial is \\(0\\) at \\(k\\) distinct points. This is only possible when \\(f \\equiv 0\\). \\(\\blacksquare\\)\n\n\nFinish\nNotice that\n\\[\nS(f) = (f(t_1), \\dotsc, f(t_k)) = \\sum_j f(t_j)e_j\n\\] Since \\(S\\) is an isomorphism, \\[\nf = \\sum_j f(t_j)S^{-1}(e_j)\n\\] Let \\(a_j = \\int_0^1 (S^{-1}(e_j))(x) dx\\), then, clearly, \\[\n\\int_0^1 f(x)dx = \\int_0^1 \\sum_j f(t_j)(S^{-1}(e_j))(x) dx\\] \\[\\int_0^1 f(x) dx = \\sum_j f(t_j) \\left(\\int_0^1 (S^{-1}(e_j))(x) dx\\right) = \\sum_j a_j f(t_j) \\blacksquare\n\\]"
  },
  {
    "objectID": "posts/shannon-cardmagic-trick/shannon-cardmagic-trick.html",
    "href": "posts/shannon-cardmagic-trick/shannon-cardmagic-trick.html",
    "title": "Shannon’s Card Magic Trick",
    "section": "",
    "text": "This was my statistics project at ISI Sem 1. My team had: Myself, Siddhartha, Ayan, Drishti, Aman, Mrittika. Thanks to everyone for their efforts."
  },
  {
    "objectID": "posts/shannon-cardmagic-trick/shannon-cardmagic-trick.html#setup",
    "href": "posts/shannon-cardmagic-trick/shannon-cardmagic-trick.html#setup",
    "title": "Shannon’s Card Magic Trick",
    "section": "Setup",
    "text": "Setup\n\nThe magician sends you a deck of cards. You riffle shuffle it three times. You pick the card from the top and put it back in the deck, somewhere. You send the deck back to the magician. Can he find the chosen card?\n\nWhat do you think? Well, I guess I wouldn’t have asked this question if this weren’t possible. Yep - it is possible to do it reliably well.\nI couldn’t believe it myself. However, I think it will make more sense when I present the algorithm which was (apparently) discovered by Shannon. We will talk about this in part A. And implement it in part B. In the subsequent parts, we investigate what happens if we play with the setup a little bit."
  },
  {
    "objectID": "posts/shannon-cardmagic-trick/shannon-cardmagic-trick.html#part-a-shannons-algorithm",
    "href": "posts/shannon-cardmagic-trick/shannon-cardmagic-trick.html#part-a-shannons-algorithm",
    "title": "Shannon’s Card Magic Trick",
    "section": "Part A: Shannon’s Algorithm",
    "text": "Part A: Shannon’s Algorithm\nRemember the original orientation of the deck of cards. Label the cards in this orientation \\[\n    \\{1,2,\\cdots,52\\}\n\\]\nNow, we define rising sequence decomposition. To decompose a deck into its rising sequences we go through the following algorithm\n\n\nAlgorithm:\n\nStart with 1.\nFind the next number, If it is after the previous number, goto step 2. Else, continue.\nThis is a rising sequence. Start with the next unconsidered number, and goto step 2.\n\n\nFor example, if the deck is \\(\\{4,3,5,1,2\\}\\). we go \\(1\\to 2 \\implies (1,2)\\), \\(3 \\implies (3)\\), \\(4 \\to 5 \\implies (4,5)\\), thus \\(\\{4,3,5,1,2\\} \\implies (1,2)(3)(4,5)\\).\nWell, it’s time to reveal the secret algorithm that Shannon came up with:\n\n\n\nAlgorithm:\nPerform the rising sequence decomposition of the final deck. There exists a unique rising sequence singleton in this deck - this is the picked card.\n\nOur team implemented the algorithm in R and the results were extremely satisfactory."
  },
  {
    "objectID": "posts/shannon-cardmagic-trick/shannon-cardmagic-trick.html#part-b-implementation",
    "href": "posts/shannon-cardmagic-trick/shannon-cardmagic-trick.html#part-b-implementation",
    "title": "Shannon’s Card Magic Trick",
    "section": "Part B: Implementation",
    "text": "Part B: Implementation\n\nVersion 1: Distribution fitting\nWe first cut a standard deck 100 times (LOL IN REAL LIFE) and we recorded the number of cards in the smaller deck (Let this vector be \\(X\\)). I was going to fit the Gaussian distribution over the vector \\(c(X,52-X)\\).\nHowever, I noticed my skill issue when @Ayan pointed out that this dataset would not be IID. To fix this issue, I tossed a coin 100 times and picked either \\(x \\text{ or } 52-x\\) for every \\(x \\in X\\). Fitting the Gaussian distribution over this we ended up with\nfloor(rnorm(1, mean=25.78, sd = 2.3046))\nEverything else was fairly easy to implement, I had quite some fun while making this. This empirically confirms that the algorithm works with pretty high probabilities \\(\\left(\\sim 91\\%\\right)\\).\nWell, I know the code is probably not human-readable (moreso because it was written by me, lol), so, I work with the following functions: RiffleShuffle, Switch, RisingSingleton, Process, and SumCalculator. Here’s what’s special about each of them:\n\nRiffleShuffle(Deck): This first splits the deck according to the fitted distribution. Then, it stores a counter of the number of cards in the Left and Right hands (LeftHand, RightHand). My assumption is: the probability that the “next” card is from the Left hand is \\(\\frac{\\texttt{LeftHand}}{\\texttt{LeftHand + RightHand}}\\) and similarly for the Right hand.\nSwitch(Deck, c(x, y)): The \\(x^{\\text{th}}\\) index card is moved to the \\(y^{\\text{th}}\\) index in the deck.\nRisingSingleton(Deck): Well, this is interesting. I first create the index array which stores the location of the \\(i^{\\text{th}}\\) card in the Deck. Then - note that if there is a RisingSingleton: there is an element \\(x\\) such that \\(\\texttt{index}[x+1] &lt; \\texttt{index}[x]\\) and \\(\\texttt{index}[x-1] &gt; \\texttt{index}[x]\\). The weird condition in the code is to deal with the edgecases, so don’t worry about that. At last, it counts the total number of rising singletons and returns the pair \\((\\texttt{(Sum(RisingSingleton) == 1)}, \\texttt{LastSingleton})\\).\nProcess: This simulates the whole setup, and returns the boolean \\((\\texttt{(Sum(RisingSingleton) == 1) AND (LastSingleton == CorrectCard)})\\) which amounts to checking whether we get what we want.\nSumCalculator: This function carries out Process 10000 times and finds the percentage of times it gets the card right.\n\n\n#Cards is the permutation _Sigma_.\n\nDataset = c(26,26,24,26,26,25,26,26,25,23,25,26,24,26,24,26,26,23,20,26,23,22,25,23,26,26,23,25,23,25,25,25,25,26,25,23,25,24,26,25,26,23,26,23,26,24,26,24,25,24,25,23,24,25,22,21,25,25,25,21,23,24,23,21,26,25,25,24,24,25,24,25,24,24,23,25,21,25,26,26,23,25,25,23,21,24,21,25,25,22,24,25,26,23,24,25,19,25,23,25)\n\n\nRiffleShuffle &lt;- function(Cards){\n  ### Riffle shuffles the vector of Cards using\n  ### L/(L+R), R/(L+R) probabilities to each hand. \n  NewDeck = vector()\n  split = floor(rnorm(1, mean=25.78, sd = 2.3046))\n\n  LeftHand = Cards[1:split]\n  RightHand = Cards[(split+1):52]\n  for(x in 1:52){\n    L &lt;- length(LeftHand)\n    R &lt;- length(RightHand)\n    hand = sample(c(\"L\", \"R\"), 1, prob=c(L,R))\n    \n    if(hand == \"L\"){\n      card = LeftHand[1]\n      LeftHand &lt;- if (L != 1) LeftHand[2:L] else vector()\n      NewDeck = append(NewDeck, card)\n    }\n    else{\n      card = RightHand[1]\n      RightHand &lt;- if (R != 1) RightHand[2:R] else vector()\n      NewDeck = append(NewDeck, card)\n    }\n  }\n  \n  return(NewDeck)\n}\n\nSwitch &lt;- function(Cards, vals) {\n  # 1 &lt;= y &lt;= 52\n  # 1 &lt;= x &lt;= 52\n  # Logic: xth index card is moved at yth index\n  x = vals[1]\n  y = vals[2]\n  NewCards = vector()\n  for (i in 1:length(Cards)) {\n    if (i != x) {\n      NewCards = append(NewCards, Cards[i])\n    }\n  }\n  if (y != 1) {\n    if (y != 52) {\n      NewCards = append(NewCards, Cards[x], after = y - 1)\n    } else {\n      NewCards = append(NewCards, Cards[x])\n    }\n  } else {\n    NewCards = append(Cards[x], NewCards)\n  }\n  return(NewCards)\n}\n\nRisingSingleton &lt;- function(array){\n  ### Checks if there is a unique Rising Singleton and returns the singleton.\n  index = numeric(0)\n  for (i in 1:52){\n    index[array[i]] = i\n  }\n  Sum = 0\n  SingletonCard = 0\n  for (i in 1:52){\n    if((index[i] &gt;= index[min((i+1), 52)]) & (index[i] &lt;= index[max((i-1), 1)])){\n      Sum = Sum + 1\n      SingletonCard = i\n    }\n  }\n  return(c((Sum == 1), SingletonCard))\n}\n\nProcess &lt;- function(Cards){\n  ### Performs the whole process and outputs whether there\n  ### is a unique Rising Singleton\n  Cards = RiffleShuffle(Cards)\n  Cards = RiffleShuffle(Cards)\n  Cards = RiffleShuffle(Cards)\n  \n  vals = c(1, rbinom(1, 52, 0.5))\n  PickedCard = Cards[1]\n  Cards = Switch(Cards, vals)\n\n  RSCheck = RisingSingleton(Cards)\n  return((RSCheck[1])&(RSCheck[2] == PickedCard))\n}\n\nSumCalculator &lt;- function(Cards){\n  ### Simulates Process 10000 and counts how many times  \n  ### there is a unique Rising Singleton which is also indeed\n  ### the picked card.\n  Sum = 0\n  for(i in 1:10000){\n    Sum = Sum + Process(Cards)\n  }\n  return(Sum)\n}\n\nCards = 1:52\nSumCalculator(Cards)/10000 * 100\n\n[1] 91.91\n\n\nAlso, @Siddhartha implemented this in Python\n\nimport numpy as np\n\nimport random\ndef riffle_shuffle(deck):\n    cut_index = int(np.random.normal(25.78, 2.3046))\n    cut_index = max(1, min(cut_index, 51))\n    left_hand = deck[:cut_index]\n    right_hand = deck[cut_index:]\n    shuffled_deck = []\n    while left_hand or right_hand:\n        if len(right_hand) &gt; 0 and np.random.rand() &lt;= len(right_hand) / (len(left_hand) + len(right_hand)):\n            shuffled_deck.append(right_hand.pop(0))\n        else:\n            shuffled_deck.append(left_hand.pop(0))\n    return shuffled_deck\n\ndef swap_first_card(deck):\n    index = int(list(np.random.binomial(52, 0.5, 1))[0])\n    index = min(index, 52)\n    deck[0]=deck.pop(0)\n    deck.insert(index,deck[0])\ndef rising_singleton(array):\n    # Create an index array to store the positions of values in the input array\n    index = [0] * 52\n\n    # Populate the index array with the positions of values in the input array\n    for i in range(52):\n        index[array[i] - 1] = i\n\n    Sum = 0\n    SingletonCard = 0\n\n    # Check if there is a unique Rising Singleton\n    for i in range(52):\n        if (index[i] &gt;= index[min(i + 1, 51)]) and (index[i] &lt;= index[max(i - 1, 0)]):\n            Sum += 1\n            SingletonCard = i + 1\n\n    return [Sum == 1, SingletonCard]\n\nunique_singleton_count = 0\n\n# Repeat the process 10,000 times\nfor x in range(10000):\n    deck = list(range(1,53))\n    for y in range(3):\n        deck = riffle_shuffle(deck)\n    swap_first_card(deck)\n    is_unique_singleton,z = rising_singleton(deck)\n    if is_unique_singleton:\n        unique_singleton_count += 1\n\n# Percentage of unique singletons\nprint(\"Percentage: \", unique_singleton_count/100)\n\nPercentage:  92.38\n\n\n\n\n\nVersion 2: Splitting using \\(\\operatorname{Bin}\\left(52, \\frac{1}{2}\\right)\\)\n#Cards is the permutation _Sigma_.\n\nRiffleShuffle &lt;- function(Cards){\n  ...\n  split = rbinom(1, 52, 1/2)\n  ...\n}\nWhere I only change how I perform the split. This results in about \\(\\left(89\\%\\right)\\)."
  },
  {
    "objectID": "posts/shannon-cardmagic-trick/shannon-cardmagic-trick.html#part-c-playing-around",
    "href": "posts/shannon-cardmagic-trick/shannon-cardmagic-trick.html#part-c-playing-around",
    "title": "Shannon’s Card Magic Trick",
    "section": "Part C: Playing Around",
    "text": "Part C: Playing Around\nWe can now tinker with the setup to see what happens when we change things a little bit. Note that we picked the card from the top and put it back somewhere. It makes sense to ask: what happens when we pick it from anywhere? Well, here’s a plot in R which showcases what happens when we vary the location of the picked card.\n\n\n\n\n\nWhich makes sense because the way we are choosing the position to put the card into is a function symmetric around 26."
  },
  {
    "objectID": "no_show/post-with-code/index.html",
    "href": "no_show/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cold Reflections",
    "section": "",
    "text": "So Far Yet So Close: How Independence is Almost Dependence\n\n\n\n\n\n\n\nprobability theory\n\n\nstatistics\n\n\nmath\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2024\n\n\nHimadri Mandal\n\n\n\n\n\n\n  \n\n\n\n\n\\(k+1\\) points uniquely determine a \\(k\\) degree polynomial: A cool problem\n\n\n\n\n\n\n\nalgebra\n\n\nmath\n\n\n\n\n\n\n\n\n\n\n\nDec 10, 2023\n\n\nHimadri Mandal\n\n\n\n\n\n\n  \n\n\n\n\nAxiom of Choice, the Zorn’s Lemma, and the Foundations of Mathematics: Set Theory Part I\n\n\n\n\n\n\n\nset theory\n\n\nmath\n\n\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\nHimadri Mandal\n\n\n\n\n\n\n  \n\n\n\n\nShannon’s Card Magic Trick\n\n\n\n\n\n\n\nisi\n\n\nstatistics\n\n\nmath\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2023\n\n\nHimadri Mandal\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/nelson/nelson.html#theorem-1",
    "href": "posts/nelson/nelson.html#theorem-1",
    "title": "So Far Yet So Close: How Independence is Almost Dependence",
    "section": "Theorem",
    "text": "Theorem\n\nLet \\(X,Y\\) be independent continuous random variables on \\((\\mathbb{R}, \\mathcal{B}, P)\\). For all \\(\\epsilon &gt; 0\\) there exist deterministically dependent \\(U,V\\) on the same probability space with \\(F_U = F_X, F_V = F_Y\\) and \\(\\sup_{(a,b) \\in \\mathbb{R}^2} |F_{U,V}(a,b) - F_{X,Y}(a,b)| &lt; \\epsilon\\)."
  }
]